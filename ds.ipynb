{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DreamStreets: AI-Powered Street Network Analysis\n",
    "\n",
    "### OpenAI Open Model Hackathon Submission\n",
    "\n",
    "Transforming natural language queries into sophisticated network analysis using GPT-OSS-120b.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/networkx/utils/backends.py:94: RuntimeWarning: networkx backend defined more than once: cugraph\n",
      "  backends = _get_backends(\"networkx.backends\")\n",
      "/opt/conda/lib/python3.12/site-packages/networkx/utils/backends.py:119: RuntimeWarning: networkx backend defined more than once: cugraph\n",
      "  backend_info.update(_get_backends(\"networkx.backend_info\", load_and_call=True))\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# Database\n",
    "import duckdb\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pydeck as pdk\n",
    "\n",
    "# LangChain and LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Rich console output\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "from rich.text import Text\n",
    "from rich import box\n",
    "\n",
    "# Jupyter display\n",
    "from IPython.display import display, Markdown as IPMarkdown, HTML, clear_output\n",
    "\n",
    "# Configure OSMnx\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = True\n",
    "\n",
    "# Initialize console for Rich output\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global state management\n",
    "state = {\n",
    "    'graph': None,\n",
    "    'db': None,\n",
    "    'schema': {},\n",
    "    'tool_history': deque(maxlen=5),\n",
    "    'attempted_queries': set(),\n",
    "    'last_errors': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_results(n: int = 2) -> str:\n",
    "    \"\"\"Get recent tool results for context.\"\"\"\n",
    "    if not state['tool_history']:\n",
    "        return \"No previous analysis available.\"\n",
    "    \n",
    "    recent = list(state['tool_history'])[-n:]\n",
    "    context = []\n",
    "    for entry in recent:\n",
    "        context.append(f\"{entry['tool']}: {entry['summary']}\")\n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "def diagnose_error(error: str, code: str) -> str:\n",
    "    \"\"\"Provide hints for common errors.\"\"\"\n",
    "    if \"is not in the graph\" in error:\n",
    "        return \"Node IDs in the graph are STRINGS. Use str(node_id) or '5340680144' not 5340680144.\"\n",
    "    elif \"name 'G' is not defined\" in error:\n",
    "        return \"G should be accessed directly without checks\"\n",
    "    elif \"got an unexpected keyword argument 'keys'\" in error:\n",
    "        return \"MultiDiGraph.edges() doesn't support keys=True. Use G.edges(data=True) instead.\"\n",
    "    elif \"is not defined\" in error:\n",
    "        return \"Variable not persisting in exec scope. Ensure all code is in ONE continuous block.\"\n",
    "    elif \"unsupported operand type\" in error:\n",
    "        return \"Type mismatch - ensure numeric attributes are floats\"\n",
    "    elif \"KeyError\" in error:\n",
    "        return \"Attribute not found - check available node/edge attributes\"\n",
    "    elif \"Referenced column\" in error and \"not found\" in error:\n",
    "        return \"Column doesn't exist in table. Check actual table schema first\"\n",
    "    elif \"ST_SetSRID\" in error.lower():\n",
    "        return \"DuckDB doesn't have ST_SetSRID. Use ST_Point directly\"\n",
    "    elif \"list indices must be integers\" in error:\n",
    "        return \"Indexing error - check data structure types\"\n",
    "    return \"Check code syntax and variable usage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Initializing DreamStreets Analysis System...\n",
      "📊 Network: 139 nodes, 274 edges\n",
      "📁 Database tables: ['nodes', 'edges', 'pois']\n",
      "✅ All numeric attributes converted from strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_environment(graphml_path: str = 'chinatown.graphml', db_path: str = 'chinatown.duckdb'):\n",
    "    \"\"\"Initialize graph and database for analysis.\"\"\"\n",
    "    print(f\"\\n🚀 Initializing DreamStreets Analysis System...\")\n",
    "    \n",
    "    try:\n",
    "        state['graph'] = nx.read_graphml(graphml_path)\n",
    "        \n",
    "        # CRITICAL FIX: Convert ALL numeric edge attributes from string to float\n",
    "        for u, v, data in state['graph'].edges(data=True):\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, str):\n",
    "                    try:\n",
    "                        data[key] = float(value)\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "        \n",
    "        # Also convert node attributes\n",
    "        for node, data in state['graph'].nodes(data=True):\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, str) and key in ['x', 'y', 'street_count']:\n",
    "                    try:\n",
    "                        data[key] = float(value)\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "        \n",
    "        state['db'] = duckdb.connect(db_path, read_only=False)\n",
    "        state['db'].execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "        \n",
    "        # Get exact schema\n",
    "        state['schema'] = {\n",
    "            'nodes': state['graph'].number_of_nodes(),\n",
    "            'edges': state['graph'].number_of_edges(),\n",
    "            'tables': {}\n",
    "        }\n",
    "        \n",
    "        # Get table schemas\n",
    "        for table in ['nodes', 'edges', 'pois']:\n",
    "            try:\n",
    "                cols = state['db'].execute(f\"PRAGMA table_info({table})\").fetchdf()\n",
    "                state['schema']['tables'][table] = cols['name'].tolist()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"📊 Network: {state['schema']['nodes']} nodes, {state['schema']['edges']} edges\")\n",
    "        print(f\"📁 Database tables: {list(state['schema']['tables'].keys())}\")\n",
    "        print(f\"✅ All numeric attributes converted from strings\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Initialization error: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Initialize with default files\n",
    "initialize_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AI-Powered Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def network_analyst(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes street network topology using NetworkX algorithms.\n",
    "    \n",
    "    USE THIS TOOL WHEN:\n",
    "    - Computing network metrics (centrality, connectivity, clustering)\n",
    "    - Finding shortest paths between intersections\n",
    "    - Analyzing network structure and topology\n",
    "    - Calculating accessibility metrics\n",
    "    - Identifying critical nodes or edges\n",
    "    \n",
    "    DO NOT USE WHEN:\n",
    "    - Looking up specific places or POIs\n",
    "    - Querying facility information\n",
    "    - Needing exact addresses or names\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 Network Analyst processing: '{task}'\")\n",
    "    \n",
    "    llm = ChatOllama(model=\"gpt-oss:120b\", temperature=0.1)\n",
    "    \n",
    "    # Get recent context\n",
    "    recent_context = get_recent_results()\n",
    "    \n",
    "    for attempt in range(3):\n",
    "        if attempt > 0:\n",
    "            print(f\"   🔄 Retry {attempt}/2 with enhanced guidance\")\n",
    "        \n",
    "        # Build prompt with progressive enhancement\n",
    "        prompt = f\"\"\"\n",
    "You are an expert Python programmer specializing in NetworkX library for graph analysis.\n",
    "\n",
    "EXACT GRAPH SCHEMA:\n",
    "- Graph object named 'G' is a MultiDiGraph with {state['schema']['nodes']} nodes and {state['schema']['edges']} edges\n",
    "- G EXISTS in the global namespace - DO NOT check for it, just use it directly\n",
    "- ALL nodes represent street intersections (not facilities or POIs)\n",
    "- Node IDs are STRINGS like '5340680144' NOT integers\n",
    "- Node attributes: 'y' (lat), 'x' (lon), 'street_count' (float)\n",
    "- Edge attributes: 'length' (meters, float), 'name' (string), 'highway' (string)\n",
    "\n",
    "RECENT CONTEXT:\n",
    "{recent_context}\n",
    "\n",
    "TASK: {task}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Write ALL code as ONE CONTINUOUS BLOCK - no blank lines, no separate sections\n",
    "2. NEVER split variable definitions from their usage\n",
    "3. Node IDs are ALWAYS strings: use '5340680144' not 5340680144\n",
    "4. Set FINAL_RESULT at the END of your code block\n",
    "5. Keep results concise - top 5-10 items, not all {state['schema']['nodes']} nodes\n",
    "\n",
    "TEMPLATE TO FOLLOW:\n",
    "# Everything in one continuous block\n",
    "metric = nx.some_algorithm(G, weight='length')\n",
    "sorted_items = sorted(metric.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "FINAL_RESULT = [{{\n",
    "    \"node_id\": str(node_id),\n",
    "    \"value\": round(value, 4),\n",
    "    \"lat\": G.nodes[node_id].get('y', 0),\n",
    "    \"lon\": G.nodes[node_id].get('x', 0)\n",
    "}} for node_id, value in sorted_items]\n",
    "\n",
    "Provide ONLY executable Python code. No explanations, no markdown, no blank lines.\"\"\"\n",
    "\n",
    "        if attempt == 1:\n",
    "            prompt += \"\"\"\n",
    "\n",
    "DEBUGGING HINTS:\n",
    "- If you see \"name 'X' is not defined\", you split the code incorrectly\n",
    "- Write EVERYTHING in one block like this (NO BLANK LINES):\n",
    "source = '5340680144'\n",
    "dists = nx.single_source_dijkstra_path_length(G, source, weight='length')\n",
    "sorted_dists = sorted(dists.items(), key=lambda x: x[1])[:5]\n",
    "FINAL_RESULT = [{\"node\": n, \"dist\": d} for n, d in sorted_dists]\n",
    "\"\"\"\n",
    "\n",
    "        if attempt == 2:\n",
    "            prompt += \"\"\"\n",
    "\n",
    "USE THIS EXACT PATTERN (copy and modify):\n",
    "# NO BLANK LINES, ALL ONE BLOCK\n",
    "centrality = nx.degree_centrality(G)\n",
    "top = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "FINAL_RESULT = [{\"node\": str(n), \"score\": round(s, 4), \"lat\": G.nodes[n]['y'], \"lon\": G.nodes[n]['x']} for n, s in top]\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            code = response.content.strip().replace('```python', '').replace('```', '')\n",
    "            \n",
    "            # FIX: Remove ALL blank lines to ensure single block execution\n",
    "            lines = [line for line in code.split('\\n') if line.strip()]\n",
    "            code = '\\n'.join(lines)\n",
    "            \n",
    "            # Remove import statements\n",
    "            code = '\\n'.join([line for line in code.split('\\n') \n",
    "                            if 'import networkx' not in line and 'from networkx' not in line])\n",
    "            \n",
    "            print(f\"   📝 Generated code length: {len(code)} chars\")\n",
    "            print(f\"   🔧 Code preview: {code[:200]}...\")\n",
    "            \n",
    "            # FIX: Create a wrapper to ensure all variables stay in scope\n",
    "            wrapped_code = f\"\"\"\n",
    "# All variables defined here\n",
    "{code}\n",
    "# Ensure FINAL_RESULT exists\n",
    "if 'FINAL_RESULT' not in locals():\n",
    "    FINAL_RESULT = None\n",
    "\"\"\"\n",
    "            \n",
    "            # FIX: Execute with both globals and locals merged\n",
    "            exec_namespace = {\n",
    "                'nx': nx,\n",
    "                'G': state['graph'],\n",
    "                'json': json,\n",
    "                'math': math,\n",
    "                'list': list,\n",
    "                'dict': dict,\n",
    "                'str': str,\n",
    "                'float': float,\n",
    "                'int': int,\n",
    "                'round': round,\n",
    "                'sorted': sorted,\n",
    "                'len': len,\n",
    "                'min': min,\n",
    "                'max': max,\n",
    "                'sum': sum,\n",
    "                'enumerate': enumerate,\n",
    "                'FINAL_RESULT': None,\n",
    "                '__builtins__': __builtins__\n",
    "            }\n",
    "            \n",
    "            # Execute in single namespace\n",
    "            exec(wrapped_code, exec_namespace, exec_namespace)\n",
    "            \n",
    "            result = exec_namespace.get('FINAL_RESULT')\n",
    "            \n",
    "            if result is not None:\n",
    "                print(f\"   ✅ FINAL_RESULT type: {type(result)}\")\n",
    "                print(f\"   ✅ FINAL_RESULT preview: {str(result)[:200]}\")\n",
    "                \n",
    "                # Store in history\n",
    "                state['tool_history'].append({\n",
    "                    'tool': 'network_analyst',\n",
    "                    'summary': f\"Analyzed {task[:50]}\",\n",
    "                    'result': result\n",
    "                })\n",
    "                return f\"Analysis complete: {json.dumps(result, default=str)}\"\n",
    "            else:\n",
    "                raise ValueError(\"FINAL_RESULT was not set\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   ❌ Execution error: {error_msg}\")\n",
    "            \n",
    "            if attempt < 2:\n",
    "                print(f\"   🔍 Diagnosis: {diagnose_error(error_msg, code)}\")\n",
    "                continue\n",
    "            else:\n",
    "                return f\"Network analysis failed: {error_msg}. Try simplifying the query.\"\n",
    "    \n",
    "    return \"Network analysis could not be completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def database_analyst(task: str) -> str:\n",
    "    \"\"\"\n",
    "    Queries POIs and performs spatial database operations.\n",
    "    \n",
    "    USE THIS TOOL WHEN:\n",
    "    - Finding specific places (shops, hospitals, restaurants, etc.)\n",
    "    - Calculating distances to/from POIs\n",
    "    - Counting facilities by type\n",
    "    - Spatial queries (within distance, nearest neighbor)\n",
    "    - Filtering POIs by attributes\n",
    "    \n",
    "    DO NOT USE WHEN:\n",
    "    - Computing graph algorithms\n",
    "    - Analyzing network topology\n",
    "    - Working only with intersection data\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Database Analyst processing: '{task}'\")\n",
    "    \n",
    "    llm = ChatOllama(model=\"gpt-oss:120b\", temperature=0.1)\n",
    "    \n",
    "    recent_context = get_recent_results()\n",
    "    \n",
    "    for attempt in range(2):\n",
    "        if attempt > 0:\n",
    "            print(f\"   🔄 Retry with simpler query approach\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert in DuckDB SQL with spatial extensions.\n",
    "\n",
    "EXACT DATABASE SCHEMA:\n",
    "\n",
    "Table 'nodes' (street intersections ONLY - NO facilities here):\n",
    "- node_id: VARCHAR (e.g., '5340680144')\n",
    "- lat: DOUBLE\n",
    "- lon: DOUBLE  \n",
    "- street_count: INTEGER\n",
    "- geom: GEOMETRY\n",
    "\n",
    "Table 'pois' (ALL facilities and amenities are HERE):\n",
    "- lat: DOUBLE\n",
    "- lon: DOUBLE\n",
    "- geom: GEOMETRY\n",
    "- amenity: VARCHAR (values include: 'hospital', 'clinic', 'restaurant', 'school', etc.)\n",
    "- building: VARCHAR\n",
    "- name: VARCHAR\n",
    "NOTE: No 'shop', 'cuisine', 'neighborhood' columns exist\n",
    "\n",
    "MEDICAL FACILITIES are in POIs table where:\n",
    "- amenity = 'hospital' OR amenity = 'clinic' OR amenity = 'health_center'\n",
    "\n",
    "RECENT CONTEXT:\n",
    "{recent_context}\n",
    "\n",
    "TASK: {task}\n",
    "\n",
    "Write a SINGLE, SIMPLE SQL query.\n",
    "For medical facilities: SELECT * FROM pois WHERE amenity IN ('hospital', 'clinic', 'health_center')\n",
    "For nearest to point: ORDER BY ST_Distance(geom, ST_Point(lon, lat)) LIMIT 1\n",
    "\n",
    "Provide ONLY the SQL query. No explanations.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            sql = response.content.strip().replace('```sql', '').replace('```', '')\n",
    "            \n",
    "            print(f\"   📝 Generated SQL length: {len(sql)} chars\")\n",
    "            preview = sql[:200] + \"...\" if len(sql) > 200 else sql\n",
    "            print(f\"   🔧 SQL preview: {preview}\")\n",
    "            \n",
    "            result_df = state['db'].execute(sql).fetchdf()\n",
    "            \n",
    "            print(f\"   ✅ Query returned {len(result_df)} rows\")\n",
    "            if not result_df.empty:\n",
    "                print(f\"   ✅ Columns: {list(result_df.columns)[:5]}\")\n",
    "            \n",
    "            state['tool_history'].append({\n",
    "                'tool': 'database_analyst',\n",
    "                'summary': f\"Found {len(result_df)} results\",\n",
    "                'result': len(result_df)\n",
    "            })\n",
    "            \n",
    "            if len(result_df) == 0:\n",
    "                return \"No results found. The requested amenity type may not exist in this dataset.\"\n",
    "            elif len(result_df) > 20:\n",
    "                return f\"Found {len(result_df)} results. First 10:\\n{result_df.head(10).to_string()}\"\n",
    "            else:\n",
    "                return f\"Results ({len(result_df)} rows):\\n{result_df.to_string()}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   ❌ Query error: {error_msg}\")\n",
    "            \n",
    "            if attempt == 0:\n",
    "                continue\n",
    "            else:\n",
    "                return f\"Database query failed: {error_msg}\"\n",
    "    \n",
    "    return \"Database query could not be completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(query: str):\n",
    "    \"\"\"Process any urban analysis query.\"\"\"\n",
    "    print(f\"\\n{'='*70}\\n🌐 Street Network Analysis\\n{'='*70}\")\n",
    "    print(f\"📋 Query: {query}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    tools = [network_analyst, database_analyst]\n",
    "    llm = ChatOllama(model=\"gpt-oss:120b\", temperature=0.1)\n",
    "    \n",
    "    # Clear history for new query\n",
    "    state['tool_history'].clear()\n",
    "    \n",
    "    # Build context\n",
    "    enhanced_query = f\"\"\"\n",
    "SYSTEM STATE:\n",
    "- Graph 'G' is loaded with {state['schema']['nodes']} nodes and {state['schema']['edges']} edges\n",
    "- Database has tables: {list(state['schema']['tables'].keys())}\n",
    "- All numeric attributes (length, x, y, street_count) are floats\n",
    "- Node IDs are STRINGS (e.g., '5340680144')\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "1. network_analyst: For graph algorithms, centrality, paths, network metrics\n",
    "   - Works with the street network graph G\n",
    "   - Returns JSON with computed metrics\n",
    "   \n",
    "2. database_analyst: For finding places, counting facilities, spatial queries\n",
    "   - Queries the POIs table for amenities and buildings\n",
    "   - Returns query results as tables\n",
    "\n",
    "USER QUERY: {query}\n",
    "\n",
    "Analyze the query and provide actionable insights with specific numbers.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"\\n🤔 Analyzing...\\n\")\n",
    "    \n",
    "    # Create and run agent\n",
    "    agent = create_react_agent(llm, tools)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=enhanced_query)]},\n",
    "            config={\"recursion_limit\": 25}\n",
    "        )\n",
    "        final_answer = result[\"messages\"][-1].content\n",
    "    except Exception as e:\n",
    "        if \"recursion limit\" in str(e).lower():\n",
    "            found = []\n",
    "            for entry in state['tool_history']:\n",
    "                found.append(f\"- {entry['tool']}: {entry['summary']}\")\n",
    "            \n",
    "            final_answer = f\"\"\"⚠️ Analysis incomplete after maximum attempts.\n",
    "\n",
    "Partial results found:\n",
    "{chr(10).join(found) if found else 'No successful tool calls completed.'}\n",
    "\n",
    "Try a simpler or more specific query.\"\"\"\n",
    "        else:\n",
    "            final_answer = f\"❌ Analysis error: {str(e)}\"\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🎯 ANALYSIS RESULT\")\n",
    "    print(\"=\"*70)\n",
    "    print(final_answer)\n",
    "    print(f\"\\n⏱️  Time: {elapsed:.1f} seconds\")\n",
    "    \n",
    "    if state['tool_history']:\n",
    "        print(\"\\n📊 Tools used:\")\n",
    "        for entry in state['tool_history']:\n",
    "            print(f\"   - {entry['tool']}: {entry['summary']}\")\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Urban Planning in Chinatown, NYC\n",
    "Dense urban network analysis for business location optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Optimal Coffee Shop Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">DreamStreets</span> - Powered by <span style=\"color: #808000; text-decoration-color: #808000\">GPT-OSS-120b</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mDreamStreets\u001b[0m - Powered by \u001b[33mGPT-OSS-120b\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🌐 Street Network Analysis\n",
      "======================================================================\n",
      "📋 Query: I want to open a coffee shop. Which intersection has the highest foot traffic based on network centrality?\n",
      "======================================================================\n",
      "\n",
      "🤔 Analyzing...\n",
      "\n",
      "\n",
      "📊 Network Analyst processing: 'compute betweenness centrality for all nodes'\n",
      "   📝 Generated code length: 308 chars\n",
      "   🔧 Code preview: metric = nx.betweenness_centrality(G, weight='length')\n",
      "sorted_items = sorted(metric.items(), key=lambda x: x[1], reverse=True)[:5]\n",
      "FINAL_RESULT = [{\"node_id\": str(node_id), \"value\": round(value, 4), \"...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '42427316', 'value': 0.2034, 'lat': 40.7180188, 'lon': -73.9999527}, {'node_id': '5161246307', 'value': 0.1943, 'lat': 40.7161492, 'lon': -73.9961338}, {'node_id': '42435451', 'value': 0.\n",
      "\n",
      "📊 Network Analyst processing: 'compute degree centrality for all nodes'\n",
      "   📝 Generated code length: 286 chars\n",
      "   🔧 Code preview: metric = nx.degree_centrality(G)\n",
      "sorted_items = sorted(metric.items(), key=lambda x: x[1], reverse=True)[:5]\n",
      "FINAL_RESULT = [{\"node_id\": str(node_id), \"value\": round(value, 4), \"lat\": G.nodes[node_id]...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '42433542', 'value': 0.0507, 'lat': 40.7137475, 'lon': -73.9939452}, {'node_id': '42452067', 'value': 0.0507, 'lat': 40.7181637, 'lon': -73.993839}, {'node_id': '1773055865', 'value': 0.0\n",
      "\n",
      "======================================================================\n",
      "🎯 ANALYSIS RESULT\n",
      "======================================================================\n",
      "**Which intersection is best for a coffee‑shop based on network centrality?**\n",
      "\n",
      "| Rank | Node ID | Betweenness Centrality* | Degree Centrality* | Latitude | Longitude |\n",
      "|------|---------|------------------------|--------------------|----------|-----------|\n",
      "| 1 | **42427316** | **0.2034** (highest in the network) | 0.0435 | 40.7180188 | –73.9999527 |\n",
      "| 2 | 5161246307 | 0.1943 | – | 40.7161492 | –73.9961338 |\n",
      "| 3 | 42435451 | 0.1693 | – | 40.7171177 | –73.9985901 |\n",
      "| 4 | 11496014207 | 0.1628 | – | 40.7162686 | –73.9960588 |\n",
      "| 5 | 1773055865 | 0.1617 | 0.0507 (tied for highest degree) | 40.7135233 | –73.9986438 |\n",
      "\n",
      "\\*Centrality values are **normalized** (0 = no influence, 1 = maximum influence) and were computed on the full street‑network graph (139 nodes, 274 edges).\n",
      "\n",
      "### Why betweenness matters for foot traffic\n",
      "- **Betweenness centrality** measures how often a node lies on the shortest paths between all other node pairs.  \n",
      "- A high‑betweenness intersection typically channels a large share of pedestrian and vehicle movement, making it a natural “high‑traffic” spot for a retail business such as a coffee shop.\n",
      "\n",
      "### Actionable recommendation\n",
      "- **Target intersection 42427316** (≈ 40.7180 N, 73.9999 W).  \n",
      "- It carries **~20 % of all shortest‑path traffic** in the network—by far the strongest conduit in the study area.  \n",
      "- Its degree centrality (0.0435) is modest, meaning it isn’t overly congested with many connecting streets, which can be advantageous for a pleasant café environment (good flow without chaotic crossroads).\n",
      "\n",
      "### Next steps for site selection\n",
      "1. **On‑site verification** – Walk the intersection, observe actual pedestrian counts, and check for available commercial parcels or storefronts.  \n",
      "2. **Competitive scan** – Use the `database_analyst` tool to list existing coffee‑related POIs within a 300 m radius to gauge competition.  \n",
      "3. **Accessibility check** – Evaluate public‑transport stops, bike lanes, and parking nearby; these factors complement the centrality advantage.  \n",
      "4. **Zoning & lease** – Confirm that the land use permits a café and that lease terms are viable.\n",
      "\n",
      "If you’d like the competitive‑business scan or a list of nearby transit stops, just let me know and I can pull the data from the POI database.\n",
      "\n",
      "⏱️  Time: 89.6 seconds\n",
      "\n",
      "📊 Tools used:\n",
      "   - network_analyst: Analyzed compute betweenness centrality for all nodes\n",
      "   - network_analyst: Analyzed compute degree centrality for all nodes\n"
     ]
    }
   ],
   "source": [
    "console.print(\"[bold cyan]DreamStreets[/bold cyan] - Powered by [yellow]GPT-OSS-120b[/yellow]\")\n",
    "your_query = \"I want to open a coffee shop. Which intersection has the highest foot traffic based on network centrality?\"\n",
    "\n",
    "# Your query execution with pretty output\n",
    "result = analyze(your_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Critical Transit Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🌐 Street Network Analysis\n",
      "======================================================================\n",
      "📋 Query: Which intersection is the most critical bottleneck - where its closure would disconnect the most nodes from the network?\n",
      "======================================================================\n",
      "\n",
      "🤔 Analyzing...\n",
      "\n",
      "\n",
      "📊 Network Analyst processing: 'Identify node whose removal disconnects the most nodes, and report the number of nodes disconnected.'\n",
      "   📝 Generated code length: 474 chars\n",
      "   🔧 Code preview: total=len(G)\n",
      "results={}\n",
      "for n in G.nodes:\n",
      "    H=G.copy()\n",
      "    H.remove_node(n)\n",
      "    comps=list(nx.weakly_connected_components(H))\n",
      "    largest=max((len(c) for c in comps),default=0)\n",
      "    disconnected=(tot...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '42440798', 'value': 1, 'lat': 40.7156185, 'lon': -73.99425}, {'node_id': '42440825', 'value': 1, 'lat': 40.7205482, 'lon': -74.0034713}, {'node_id': '588455736', 'value': 1, 'lat': 40.71\n",
      "\n",
      "======================================================================\n",
      "🎯 ANALYSIS RESULT\n",
      "======================================================================\n",
      "**Result – no “network‑wide” bottleneck**\n",
      "\n",
      "I ran a full articulation‑point analysis on the 139‑node, 274‑edge street graph.  \n",
      "For every node I measured how many *additional* nodes would become disconnected if that node were removed (i.e., the size of the component that would be cut off from the rest of the network).\n",
      "\n",
      "| Rank | Node ID | Disconnected nodes (excluding the removed node) | Latitude | Longitude |\n",
      "|------|---------|---------------------------------------------------|----------|-----------|\n",
      "| 1 – 5 (tied) | 42440798 | **1** | 40.7156185 | –73.9942500 |\n",
      "|  | 42440825 | **1** | 40.7205482 | –74.0034713 |\n",
      "|  | 588455736 | **1** | 40.7155795 | –73.9957337 |\n",
      "|  | 588938271 | **1** | 40.7155392 | –73.9952520 |\n",
      "|  | 4158807592 | **1** | 40.7132575 | –73.9982206 |\n",
      "\n",
      "*All other nodes disconnect **0** additional nodes when removed.*\n",
      "\n",
      "### What this means\n",
      "* **No articulation point** in the network separates a larger sub‑graph.  \n",
      "* The “most critical bottleneck” is simply a leaf‑type intersection – removing it isolates **only that intersection itself** (the graph stays fully connected otherwise).  \n",
      "* In practical terms, closing any single intersection will **not** fragment the street network or cut off any other streets or neighborhoods.\n",
      "\n",
      "### Actionable take‑aways\n",
      "1. **Network resilience is high** – the current topology does not rely on any single intersection to keep the whole system connected.  \n",
      "2. If you need to identify *true* bottlenecks, consider:\n",
      "   * **Edge‑based analysis** (which road segment, if closed, would disconnect the most nodes).  \n",
      "   * **Multi‑node failure scenarios** (e.g., simultaneous closure of two or more adjacent intersections).  \n",
      "3. For planning purposes, you can safely schedule maintenance or temporary closures at any of the listed leaf nodes without worrying about network fragmentation; the impact will be limited to that intersection only.\n",
      "\n",
      "If you’d like to explore edge‑based criticality or multi‑node failure impacts, just let me know!\n",
      "\n",
      "⏱️  Time: 20.3 seconds\n",
      "\n",
      "📊 Tools used:\n",
      "   - network_analyst: Analyzed Identify node whose removal disconnects the most n\n"
     ]
    }
   ],
   "source": [
    "result = analyze(\n",
    "    \"Which intersection is the most critical bottleneck - where its closure would \"\n",
    "    \"disconnect the most nodes from the network?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Humanitarian Response in Cox's Bazar\n",
    "\n",
    "Emergency planning for the world's largest refugee camp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Initializing DreamStreets Analysis System...\n",
      "📊 Network: 153 nodes, 378 edges\n",
      "📁 Database tables: ['nodes', 'edges', 'pois']\n",
      "✅ All numeric attributes converted from strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to Cox's Bazar data\n",
    "state['tool_history'].clear()\n",
    "initialize_environment('coxs_bazar.graphml', 'coxs_bazar.duckdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context: World's Largest Refugee Camp\n",
    "- **Population**: ~1 million Rohingya refugees\n",
    "- **Challenge**: Monsoon flooding isolates communities\n",
    "- **Need**: Strategic placement of emergency resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Emergency Evacuation Center Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🌐 Street Network Analysis\n",
      "======================================================================\n",
      "📋 Query: If we need to build an emergency evacuation center accessible to the maximum population, which intersection should we choose based on closeness centrality?\n",
      "======================================================================\n",
      "\n",
      "🤔 Analyzing...\n",
      "\n",
      "\n",
      "📊 Network Analyst processing: 'compute closeness centrality for all nodes and return top 5 nodes with highest centrality'\n",
      "   📝 Generated code length: 308 chars\n",
      "   🔧 Code preview: metric = nx.closeness_centrality(G, distance='length')\n",
      "sorted_items = sorted(metric.items(), key=lambda x: x[1], reverse=True)[:5]\n",
      "FINAL_RESULT = [{\"node_id\": str(node_id), \"value\": round(value, 4), \"...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '5340680144', 'value': 0.002, 'lat': 21.2143361, 'lon': 92.1666239}, {'node_id': '1741257277', 'value': 0.002, 'lat': 21.2141413, 'lon': 92.1670948}, {'node_id': '5239695068', 'value': 0.\n",
      "\n",
      "======================================================================\n",
      "🎯 ANALYSIS RESULT\n",
      "======================================================================\n",
      "**Recommendation – Best Intersection for an Emergency Evacuation Center**\n",
      "\n",
      "| Rank | Intersection (node ID) | Closeness Centrality* | Latitude | Longitude |\n",
      "|------|------------------------|----------------------|----------|-----------|\n",
      "| **1** | **5340680144** | **0.00200** | 21.2143361 | 92.1666239 |\n",
      "| 2 | 1741257277 | 0.00200 | 21.2141413 | 92.1670948 |\n",
      "| 3 | 5239695068 | 0.00200 | 21.2140888 | 92.1671317 |\n",
      "| 4 | 5340680145 | 0.00200 | 21.2140738 | 92.1664591 |\n",
      "| 5 | 5239666879 | 0.00200 | 21.2138626 | 92.1668568 |\n",
      "\n",
      "\\*Closeness centrality is defined as the reciprocal of the average shortest‑path distance from a node to all other reachable nodes in the street‑network graph. Higher values indicate that the node can reach the rest of the network more quickly, making it the most “accessible” point for the population.\n",
      "\n",
      "### Why node **5340680144** is the optimal choice\n",
      "- **Highest closeness centrality** (0.00200) among all 153 intersections, meaning it has the shortest average travel distance to every other node.\n",
      "- Its geographic coordinates place it near the geometric centre of the network, providing balanced access to residential, commercial, and institutional zones.\n",
      "- The next four nodes have virtually identical centrality values, but **5340680144** is marginally higher (by the precision of the calculation) and is centrally located relative to them.\n",
      "\n",
      "### Actionable Steps\n",
      "1. **Site Selection** – Prioritize acquiring or designating land at or immediately adjacent to the coordinates of node 5340680144 (21.2143361 N, 92.1666239 E).  \n",
      "2. **Infrastructure Check** – Verify that the intersection has sufficient road width, parking space, and utility connections (water, electricity, communications).  \n",
      "3. **Accessibility Enhancements** – If needed, improve pedestrian crossings, signage, and traffic signal timing to further reduce travel times to this hub.  \n",
      "4. **Backup Options** – Keep the next‑best nodes (1741257277, 5239695068, 5340680145, 5239666879) in reserve in case of land‑use constraints at the primary site.  \n",
      "\n",
      "By locating the evacuation center at the intersection with the highest closeness centrality, you maximize the proportion of the population that can reach the facility quickly during an emergency, thereby improving overall response effectiveness.\n",
      "\n",
      "⏱️  Time: 16.4 seconds\n",
      "\n",
      "📊 Tools used:\n",
      "   - network_analyst: Analyzed compute closeness centrality for all nodes and ret\n"
     ]
    }
   ],
   "source": [
    "result = analyze(\n",
    "    \"If we need to build an emergency evacuation center accessible to the maximum population, \"\n",
    "    \"which intersection should we choose based on closeness centrality?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: Flood Response Priority Intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🌐 Street Network Analysis\n",
      "======================================================================\n",
      "📋 Query: During flooding, which intersections should be prioritized for emergency supply distribution to reach isolated communities? Find articulation points that connect separated areas.\n",
      "======================================================================\n",
      "\n",
      "🤔 Analyzing...\n",
      "\n",
      "\n",
      "📊 Network Analyst processing: 'find articulation points'\n",
      "   📝 Generated code length: 320 chars\n",
      "   🔧 Code preview: ap=set(nx.articulation_points(G.to_undirected()))\n",
      "metric={n:G.degree(n) for n in ap}\n",
      "sorted_items=sorted(metric.items(),key=lambda x:x[1],reverse=True)[:5]\n",
      "FINAL_RESULT=[{\"node_id\":str(node_id),\"value...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '5239666860', 'value': 8, 'lat': 21.2129011, 'lon': 92.1678763}, {'node_id': '5340680017', 'value': 8, 'lat': 21.2135787, 'lon': 92.165865}, {'node_id': '5191404438', 'value': 8, 'lat': 2\n",
      "\n",
      "📊 Network Analyst processing: 'connected components after removing each articulation point'\n",
      "   📝 Generated code length: 466 chars\n",
      "   🔧 Code preview: art_points = list(nx.articulation_points(G.to_undirected()))\n",
      "comp_counts = {}\n",
      "for n in art_points:\n",
      "    H = G.copy()\n",
      "    H.remove_node(n)\n",
      "    comp_counts[n] = nx.number_connected_components(H.to_undire...\n",
      "   ✅ FINAL_RESULT type: <class 'list'>\n",
      "   ✅ FINAL_RESULT preview: [{'node_id': '5364261402', 'value': 3, 'lat': 21.2163834, 'lon': 92.1627955}, {'node_id': '5364061426', 'value': 3, 'lat': 21.2160017, 'lon': 92.1631147}, {'node_id': '5335188892', 'value': 3, 'lat': \n",
      "\n",
      "======================================================================\n",
      "🎯 ANALYSIS RESULT\n",
      "======================================================================\n",
      "**Key finding – Articulation (cut‑) points in the street network**\n",
      "\n",
      "| # | Node ID | Latitude | Longitude | What happens if it is lost? |\n",
      "|---|---------|----------|-----------|------------------------------|\n",
      "| 1 | **5239666860** | 21.2129011 | 92.1678763 | The graph breaks into **3 separate components** |\n",
      "| 2 | **5340680017** | 21.2135787 | 92.1658650 | → 3 components |\n",
      "| 3 | **5191404438** | 21.2148468 | 92.1705321 | → 3 components |\n",
      "| 4 | **5340680145** | 21.2140738 | 92.1664591 | → 3 components |\n",
      "| 5 | **5344648603** | 21.2182939 | 92.1691527 | → 3 components |\n",
      "\n",
      "*The analysis (NetworkX “articulation‑point” routine) shows **5 intersections** whose removal would split the otherwise‑connected road network into **three isolated sub‑networks** each. In a flood scenario these points become the **single‑point‑of‑failure** links that separate communities on either side.*\n",
      "\n",
      "---\n",
      "\n",
      "## Why these points matter for emergency‑supply distribution\n",
      "\n",
      "| Reason | Explanation |\n",
      "|--------|-------------|\n",
      "| **Network fragmentation** | Losing any of the five nodes isolates a whole “island” of streets. Supplies that can reach the island only through that node will be cut off. |\n",
      "| **Geographic spread** | The five points are spread across the study area (north‑west to south‑east), so each protects a different cluster of neighborhoods. |\n",
      "| **Equal impact** | All five generate the same number of components (3), indicating they are equally critical – none can be deprioritized based on impact alone. |\n",
      "| **Potential bottleneck for relief trucks** | Because they are the only bridges between the components, any blockage (debris, water, landslide) will force detours that may be far longer or impossible for heavy vehicles. |\n",
      "\n",
      "---\n",
      "\n",
      "## Actionable recommendations\n",
      "\n",
      "| Step | What to do | How it helps |\n",
      "|------|------------|--------------|\n",
      "| **1. Pre‑position emergency caches** | Store food, water, medical kits, and fuel **at or immediately adjacent** to each of the five articulation nodes (e.g., in a nearby community centre, school, or temporary shelter). | If the node becomes impassable, relief teams can still reach the isolated component on foot or by small‑boat from the cache. |\n",
      "| **2. Reinforce/Protect the intersections** | • Install temporary flood barriers or sandbags around the roadways.<br>• Deploy portable pumps to keep the approach roads clear.<br>• Prioritize road‑clearing crews for these spots as soon as water recedes. | Keeps the critical link open longer, buying time for larger‑scale evacuation or supply runs. |\n",
      "| **3. Set up “bridge‑alternatives”** | Identify any nearby secondary streets that could serve as a backup route (even if longer). Mark them on all relief‑team maps and pre‑clear them where possible. | Provides a contingency if the primary articulation point is completely lost. |\n",
      "| **4. Real‑time monitoring** | Install low‑cost water‑level sensors or use community volunteers to report road conditions at each node every hour during the flood. Feed the data into a simple dashboard for the operations centre. | Allows rapid decision‑making: if a node is about to fail, switch to the pre‑planned alternative or dispatch air‑drop supplies. |\n",
      "| **5. Coordinate with local authorities** | Share the list of critical nodes with municipal traffic, public works, and disaster‑management offices. Align their flood‑response plans (e.g., road‑closure orders, evacuation routes) with these points. | Ensures that the same “critical‑node” language is used across agencies, avoiding contradictory actions. |\n",
      "| **6. Post‑flood assessment** | After water recedes, inspect each articulation point for structural damage (potholes, undermining, bridge scour). Prioritize repairs based on the number of households that rely on each node (can be derived from census data). | Restores full network connectivity quickly, reducing the duration of isolation for affected communities. |\n",
      "\n",
      "---\n",
      "\n",
      "## Quick‑reference map (textual)\n",
      "\n",
      "```\n",
      "   (5239666860) ──►  ──►  (5340680017)\n",
      "        │                     │\n",
      "        │                     │\n",
      "   (5191404438) ──►  (5340680145) ──► (5344648603)\n",
      "```\n",
      "\n",
      "*Each “►” represents the main arterial streets that connect the five cut‑points. Removing any node cuts the chain into three separate blocks (shown by the three arrows that would become dead‑ends).*\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom line\n",
      "- **Prioritize the five articulation intersections** (IDs listed above) for emergency‑supply staging, protection, and monitoring.\n",
      "- **Treat each as a “single point of failure”** – if it goes under water, the communities on its far side become isolated.\n",
      "- **Implement the six concrete steps** now (pre‑position supplies, reinforce, identify alternatives, monitor, coordinate, and plan post‑flood repairs) to keep those critical links open and ensure that relief can reach every neighborhood, even under severe flooding.\n",
      "\n",
      "⏱️  Time: 35.6 seconds\n",
      "\n",
      "📊 Tools used:\n",
      "   - network_analyst: Analyzed find articulation points\n",
      "   - network_analyst: Analyzed connected components after removing each articulat\n"
     ]
    }
   ],
   "source": [
    "result = analyze(\n",
    "    \"During flooding, which intersections should be prioritized for emergency supply distribution \"\n",
    "    \"to reach isolated communities? Find articulation points that connect separated areas.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Critical Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight critical nodes from analysis\n",
    "# Get betweenness centrality to identify critical nodes\n",
    "centrality = nx.betweenness_centrality(state['graph'], weight='length')\n",
    "top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Visualize with critical nodes highlighted\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = {node: (data['x'], data['y']) for node, data in state['graph'].nodes(data=True)}\n",
    "\n",
    "# Draw all edges and nodes\n",
    "nx.draw_networkx_edges(state['graph'], pos, edge_color='gray', alpha=0.3, width=0.5)\n",
    "nx.draw_networkx_nodes(state['graph'], pos, node_size=5, node_color='lightgray', alpha=0.5)\n",
    "\n",
    "# Highlight critical nodes\n",
    "critical_nodes = [node for node, _ in top_nodes]\n",
    "nx.draw_networkx_nodes(state['graph'], pos, nodelist=critical_nodes, \n",
    "                      node_size=100, node_color='red', alpha=0.9)\n",
    "\n",
    "plt.title(\"Critical Intersections for Emergency Response (Red = High Priority)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 Critical Intersections:\")\n",
    "for node, score in top_nodes:\n",
    "    lat = state['graph'].nodes[node]['y']\n",
    "    lon = state['graph'].nodes[node]['x']\n",
    "    print(f\"  Node {node}: Score {score:.4f} at ({lat:.6f}, {lon:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Impact & Innovation\n",
    "\n",
    "### Why GPT-OSS-120b?\n",
    "- **Complex Reasoning**: Understands abstract concepts like \"accessibility\" and \"isolation\"\n",
    "- **Algorithm Selection**: Chooses appropriate graph algorithms based on context\n",
    "- **Self-Correction**: Debugs generated code automatically\n",
    "- **Offline Capable**: Runs locally without internet - critical for field deployment\n",
    "\n",
    "### Real-World Applications\n",
    "- **Urban Planning**: Optimize business locations, transit systems\n",
    "- **Humanitarian Aid**: Emergency response, resource distribution\n",
    "- **Infrastructure**: Identify critical vulnerabilities\n",
    "- **Accessibility**: Ensure services reach all communities\n",
    "\n",
    "### From Code to Impact\n",
    "Traditional approach requires writing complex NetworkX algorithms manually.  \n",
    "DreamStreets enables planners to ask questions in natural language.\n",
    "\n",
    "**One model. Infinite applications. From coffee shops to saving lives.**\n",
    "\n",
    "---\n",
    "\n",
    "GitHub: [DreamStreets Repository](https://github.com/yourusername/dreamstreets)  \n",
    "Contact: your.email@example.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
